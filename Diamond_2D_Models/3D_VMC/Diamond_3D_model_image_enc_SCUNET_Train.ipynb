{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adbfdc98-ee96-40a0-8303-4e887b1f07a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-04 15:20:34.978185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754346034.992145   80275 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754346034.996368   80275 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754346035.008660   80275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754346035.008673   80275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754346035.008675   80275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754346035.008676   80275 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-04 15:20:35.013092: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from bm3d import bm3d_rgb, BM3DProfile\n",
    "module_dir = \"/global/u2/k/kberard/SCGSR/Research/Diamond/stock_models/bm3d-4.0.3/bm3d-4.0.3/examples\" \n",
    "sys.path.insert(0, module_dir)\n",
    "from experiment_funcs import get_experiment_noise, get_psnr, get_cropped_psnr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe7a5c7-675e-40ce-b5d7-487a1b43f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from thop import profile\n",
    "from einops import rearrange \n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from timm.models.layers import trunc_normal_, DropPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "098f2929-3d5d-47b7-bcdb-15cea847764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de8dc16-f501-4c5e-ad85-1acc29815660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image denoise methods to try\n",
    "#arciteture only 2024 https://www.nature.com/articles/s41598-024-60139-x\n",
    "# cascaded gaze 2019 https://github.com/Ascend-Research/CascadedGaze\n",
    "# SwinIR 2021 https://github.com/JingyunLiang/SwinIR?tab=readme-ov-file\n",
    "#scunet, ffdnet (compared in nature paper, very close to nat perf) or dnCNN  toolbox with many models https://github.com/cszn/KAIR\n",
    "#scunet it python based \n",
    "# https://pypi.org/project/bm3d/ Bm3d also in nature paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d755537-d8f0-4658-98e5-736975bba3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# minorized reference\n",
    "with h5py.File('/global/u2/k/kberard/SCGSR/Research/Diamond/Data/density_tot_ref.h5', 'r') as file:\n",
    "    #print(\"Keys: %s\" % file.keys())\n",
    "    ref_d = file['density'][:]\n",
    "#print(ref_d)\n",
    "print(ref_d.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7582d1c8-72cb-404a-bb2a-f3abe8a2f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################################################\n",
    "def stochastic_density(d,N):\n",
    "    # poisson model\n",
    "    #  accurate and fast for all values of N\n",
    "    # N  = number of MC samples\n",
    "    assert isinstance(d,np.ndarray)\n",
    "    assert isinstance(N,(int,float,np.int64,np.float64))\n",
    "    assert N>0\n",
    "    ds = np.random.poisson(N*d)/N\n",
    "    ds*= d.sum()/ds.sum()\n",
    "    return ds\n",
    "#end def stochastic_density\n",
    "\n",
    "####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de71bb52-087e-4817-b3f1-e39e4493c157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def encode_voxel_to_rgb(x_train_3d, x_val_3d, x_test_3d,\n",
    "                        y_train_3d, y_val_3d, y_test_3d,\n",
    "                        ref_d=None, save_dir='scalers'):\n",
    "    \"\"\"\n",
    "    Encode a batch of 3D volumes by normalizing each depth slice independently and replicating to RGB.\n",
    "    Each input of shape (N, 64, 64, 64) is transformed into (N*64, 64, 64, 3).\n",
    "\n",
    "    Args:\n",
    "        *_3d: ndarray of shape (N, 64, 64, 64)\n",
    "        ref_d: optional ndarray of shape (64, 64, 64)\n",
    "        save_dir: directory to save the (min, max) scalers for each batch\n",
    "\n",
    "    Returns:\n",
    "        Tuple of:\n",
    "            x_train_rgb, x_val_rgb, x_test_rgb,\n",
    "            y_train_rgb, y_val_rgb, y_test_rgb,\n",
    "            ref_d_rgb (or None if not provided)\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    def process_batch(batch, tag):\n",
    "        N, D, H, W = batch.shape  # (N, 64, 64, 64)\n",
    "        rgb_batch = np.zeros((N * D, H, W, 3), dtype=np.float32)\n",
    "        all_mins = []\n",
    "        all_maxs = []\n",
    "\n",
    "        for i in range(N):\n",
    "            mins = []\n",
    "            maxs = []\n",
    "            for d in range(D):\n",
    "                slice_2d = batch[i, d, :, :]\n",
    "                s_min = float(slice_2d.min())\n",
    "                s_max = float(slice_2d.max())\n",
    "\n",
    "                if s_max == s_min:\n",
    "                    s_max = s_min + 1e-6  # prevent divide-by-zero\n",
    "\n",
    "                normed = (slice_2d - s_min) / (s_max - s_min)\n",
    "                rgb = np.stack([normed] * 3, axis=-1)  # shape: (64, 64, 3)\n",
    "\n",
    "                rgb_batch[i * D + d] = rgb\n",
    "                mins.append(s_min)\n",
    "                maxs.append(s_max)\n",
    "\n",
    "            all_mins.append(mins)\n",
    "            all_maxs.append(maxs)\n",
    "\n",
    "        np.savez(os.path.join(save_dir, f'{tag}_scalers.npz'),\n",
    "                 mins=np.array(all_mins), maxs=np.array(all_maxs))\n",
    "\n",
    "        return rgb_batch\n",
    "\n",
    "    x_train_rgb = process_batch(x_train_3d, 'x_train')\n",
    "    x_val_rgb   = process_batch(x_val_3d, 'x_val')\n",
    "    x_test_rgb  = process_batch(x_test_3d, 'x_test')\n",
    "    y_train_rgb = process_batch(y_train_3d, 'y_train')\n",
    "    y_val_rgb   = process_batch(y_val_3d, 'y_val')\n",
    "    y_test_rgb  = process_batch(y_test_3d, 'y_test')\n",
    "\n",
    "    # Optional: single ref volume\n",
    "    ref_d_rgb = None\n",
    "    if ref_d is not None:\n",
    "        ref_rgb = np.zeros((64, 64, 64, 3), dtype=np.float32)\n",
    "        ref_mins = []\n",
    "        ref_maxs = []\n",
    "        for d in range(64):\n",
    "            slice_2d = ref_d[d, :, :]\n",
    "            s_min = float(slice_2d.min())\n",
    "            s_max = float(slice_2d.max())\n",
    "\n",
    "            if s_max == s_min:\n",
    "                s_max = s_min + 1e-6\n",
    "\n",
    "            normed = (slice_2d - s_min) / (s_max - s_min)\n",
    "            ref_rgb[d] = np.stack([normed] * 3, axis=-1)\n",
    "            ref_mins.append(s_min)\n",
    "            ref_maxs.append(s_max)\n",
    "\n",
    "        np.savez(os.path.join(save_dir, 'ref_d_scalers.npz'),\n",
    "                 mins=np.array(ref_mins), maxs=np.array(ref_maxs))\n",
    "        ref_d_rgb = ref_rgb\n",
    "\n",
    "    return (\n",
    "        x_train_rgb, x_val_rgb, x_test_rgb,\n",
    "        y_train_rgb, y_val_rgb, y_test_rgb,\n",
    "        ref_d_rgb\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d33fda-97f9-4980-8b8b-63a9637f90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def decode_rgb_to_voxel_batch(rgb_data, scaler_path):\n",
    "    \"\"\"\n",
    "    Decode RGB-encoded batch (N*64, 64, 64, 3) back to original (N, 64, 64, 64) data\n",
    "    using per-slice min/max scalers.\n",
    "\n",
    "    Args:\n",
    "        rgb_data: ndarray of shape (N*64, 64, 64, 3)\n",
    "        scaler_path: path to `.npz` file containing 'mins' and 'maxs' arrays\n",
    "                     of shape (N, 64)\n",
    "\n",
    "    Returns:\n",
    "        reconstructed: ndarray of shape (N, 64, 64, 64)\n",
    "    \"\"\"\n",
    "    num_slices = 64\n",
    "    assert rgb_data.ndim == 4 and rgb_data.shape[1:4] == (64, 64, 3), \\\n",
    "        f\"Expected shape (N*64, 64, 64, 3), got {rgb_data.shape}\"\n",
    "\n",
    "    N = rgb_data.shape[0] // num_slices\n",
    "    assert rgb_data.shape[0] == N * num_slices, \"RGB data is not a multiple of 64 slices\"\n",
    "\n",
    "    scalers = np.load(scaler_path)\n",
    "    mins = scalers['mins']  # shape (N, 64)\n",
    "    maxs = scalers['maxs']  # shape (N, 64)\n",
    "\n",
    "    reconstructed = np.zeros((N, 64, 64, 64), dtype=np.float32)\n",
    "\n",
    "    for i in range(N):\n",
    "        for d in range(num_slices):\n",
    "            idx = i * num_slices + d\n",
    "            normed = rgb_data[idx, :, :, 0]  # Use first channel (R), they are all the same\n",
    "            s_min = mins[i, d]\n",
    "            s_max = maxs[i, d]\n",
    "            reconstructed[i, d, :, :] = normed * (s_max - s_min) + s_min\n",
    "\n",
    "    return reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e673d2-0d31-4f81-b1d0-465a43a3fa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c359b5e-e1ac-48fe-b14f-8deb014adefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating\n"
     ]
    }
   ],
   "source": [
    "x_train_rgb, x_val_rgb, x_test_rgb, \\\n",
    "y_train_rgb, y_val_rgb, y_test_rgb, \\\n",
    "ref_d_rgb = encode_voxel_to_rgb(\n",
    "    x_train, x_val, x_test,\n",
    "    y_train_3d, y_val_3d, y_test_3d,\n",
    "    ref_d=ref_d\n",
    ")\n",
    "print(\"done generating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecabdcd-bbfa-4ec0-978f-e85037846a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"import os\n",
    "save_path = '/pscratch/sd/k/kberard/SCGSR/Data/gen_dat'\n",
    "np.save(os.path.join(save_path, 'x_train_rgb_=3c.npy'), x_train_rgb)\n",
    "np.save(os.path.join(save_path, 'x_val_rgb_=3c.npy'), x_val_rgb)\n",
    "np.save(os.path.join(save_path, 'x_test_rgb_=3c.npy'), x_test_rgb)\n",
    "np.save(os.path.join(save_path, 'y_train_rgb_=3c.npy'), y_train_rgb)\n",
    "np.save(os.path.join(save_path, 'y_val_rgb_=3c.npy'), y_val_rgb)\n",
    "np.save(os.path.join(save_path, 'y_test_rgb_=3c.npy'), y_test_rgb)\n",
    "np.save(os.path.join(save_path, 'ref_d_rgb_=3c.npy'), ref_d_rgb)\n",
    "import numpy as np\"\"\"\n",
    "\n",
    "base_path = '/pscratch/sd/k/kberard/SCGSR/Data/gen_dat'\n",
    "\n",
    "x_train_rgb = np.load(f'{base_path}/x_train_rgb_=3c.npy')\n",
    "x_val_rgb   = np.load(f'{base_path}/x_val_rgb_=3c.npy')\n",
    "x_test_rgb  = np.load(f'{base_path}/x_test_rgb_=3c.npy')\n",
    "y_train_rgb = np.load(f'{base_path}/y_train_rgb_=3c.npy')\n",
    "y_val_rgb   = np.load(f'{base_path}/y_val_rgb_=3c.npy')\n",
    "y_test_rgb  = np.load(f'{base_path}/y_test_rgb_=3c.npy')\n",
    "ref_d_rgb   = np.load(f'{base_path}/ref_d_rgb_=3c.npy')\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63532194-96b4-46df-a963-bce1f1bfc05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14e89326-b00e-4161-b044-3ad0dd812b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64, 64, 3)\n",
      "(100, 64, 64, 3)\n",
      "(1000, 64, 64, 3)\n",
      "(1000, 64, 64, 3)\n",
      "(10000, 64, 64, 3)\n",
      "(100, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_rgb = x_train_rgb[54000:] \n",
    "x_val_rgb   = x_val_rgb[5400:]\n",
    "x_test_rgb  = x_test_rgb[540:] \n",
    "y_train_rgb = y_train_rgb[54000:]\n",
    "y_val_rgb   = y_val_rgb[5400:]\n",
    "y_test_rgb = y_test_rgb[540:] \n",
    "print(x_train_rgb.shape)\n",
    "print(x_test_rgb.shape)\n",
    "print(x_val_rgb.shape)\n",
    "print(y_val_rgb.shape)\n",
    "print(y_train_rgb.shape)\n",
    "print(y_test_rgb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c414fa-e44a-4daa-9a4d-166707f5d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "module_dir = \"/global/u2/k/kberard/SCGSR/Research/Diamond/stock_models/SCUNet\" \n",
    "sys.path.insert(0, module_dir)\n",
    "from models.network_scunet import SCUNet as SCUNet\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class RGBDenoiseDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        # Normalize to [0, 1] and permute axes to (N, C, H, W)\n",
    "        self.x = torch.tensor(np.transpose(x, (0, 3, 1, 2)), dtype=torch.float32) \n",
    "        self.y = torch.tensor(np.transpose(y, (0, 3, 1, 2)), dtype=torch.float32) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99a578bc-7151-4e95-808d-7dd0c008175e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3707ed7-38e1-4687-8228-6aeb83113904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Datasets\n",
    "train_dataset = RGBDenoiseDataset(x_train_rgb, y_train_rgb)\n",
    "val_dataset   = RGBDenoiseDataset(x_val_rgb, y_val_rgb)\n",
    "test_dataset  = RGBDenoiseDataset(x_test_rgb, y_test_rgb)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de1371e8-6b72-4a8f-8b15-7cfec2b4eaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n",
      "Block Initial Type: W, drop_path_rate:0.000000\n",
      "Block Initial Type: SW, drop_path_rate:0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f1c19f32060>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f1c19f32060>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f1c19f32060>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3386\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3382\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3383\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3384\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3385\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3386\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3387\u001b[39m     )\n\u001b[32m   3389\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3390\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3440\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3437\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3438\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3439\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3440\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3441\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3442\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3443\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3444\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3445\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/ultratb.py:1182\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/ultratb.py:1053\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1050\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1059\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1060\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1069\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/ultratb.py:861\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    854\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    859\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    860\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    866\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/ultratb.py:746\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m    745\u001b[39m head = \u001b[38;5;28mself\u001b[39m.prepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m.long_header)\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m records = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    748\u001b[39m frames = []\n\u001b[32m    749\u001b[39m skipped = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/IPython/core/ultratb.py:819\u001b[39m, in \u001b[36mVerboseTB.get_records\u001b[39m\u001b[34m(self, etb, context, tb_offset)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    818\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m819\u001b[39m         mod = \u001b[43minspect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtb_frame\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    820\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    821\u001b[39m             mod_name = mod.\u001b[34m__name__\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/common/software/nersc/pe/conda-envs/25.3.0/python-3.12/nersc-python/lib/python3.12/inspect.py:1016\u001b[39m, in \u001b[36mgetmodule\u001b[39m\u001b[34m(object, _filename)\u001b[39m\n\u001b[32m   1013\u001b[39m         f = getabsfile(module)\n\u001b[32m   1014\u001b[39m         \u001b[38;5;66;03m# Always map to the name the module knows itself by\u001b[39;00m\n\u001b[32m   1015\u001b[39m         modulesbyfile[f] = modulesbyfile[\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m             \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m] = module.\u001b[34m__name__\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m modulesbyfile:\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sys.modules.get(modulesbyfile[file])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/common/software/nersc/pe/conda-envs/25.3.0/python-3.12/nersc-python/lib/python3.12/posixpath.py:427\u001b[39m, in \u001b[36mrealpath\u001b[39m\u001b[34m(filename, strict)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the canonical path of the specified filename, eliminating any\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[33;03msymbolic links encountered in the path.\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m     filename = os.fspath(filename)\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     path, ok = \u001b[43m_joinrealpath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m abspath(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/common/software/nersc/pe/conda-envs/25.3.0/python-3.12/nersc-python/lib/python3.12/posixpath.py:462\u001b[39m, in \u001b[36m_joinrealpath\u001b[39m\u001b[34m(path, rest, strict, seen)\u001b[39m\n\u001b[32m    460\u001b[39m newpath = join(path, name)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     st = \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strict:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SCUNet(in_nc=3, input_resolution=64).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "# Training example\n",
    "for noisy, clean in train_loader:\n",
    "    noisy, clean = noisy.to(device), clean.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(noisy)\n",
    "    loss = loss_fn(output, clean)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "model.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319eba7c-2f1c-4786-b088-cfe4bb9c40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'scunet_trained')\n",
    "\"\"\"import torch\n",
    "from models.network_scunet import SCUNet  # wherever your SCUNet is defined\n",
    "torch.serialization.add_safe_globals([SCUNet])\n",
    "\n",
    "model = torch.load('scunet_trained', weights_only=False)\n",
    "model.eval()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7304bee9-9031-47ea-983c-983c42b1f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import utils_image as util\n",
    "\n",
    "def denoise_with_scunet(rgb_image_np, model, device='cuda'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        rgb_image_np: (H, W, 3), float32 or float64, values in [0,1]\n",
    "        model: SCUNet model\n",
    "        device: 'cuda' or 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        Denoised image (H, W, 3), uint8\n",
    "    \"\"\"\n",
    "    # Make sure image is float32 in [0,1]\n",
    "    img = rgb_image_np.astype(np.float32)\n",
    "    img_tensor = util.single2tensor4(img).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_tensor = model(img_tensor)\n",
    "    output_np = util.tensor2single(output_tensor)\n",
    "    return np.clip(output_np.transpose(1, 2, 0), 0, 1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "scunet_denoised = denoise_with_scunet(x_test_rgb[0], model, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20b7889-8da4-4ade-8afe-06adfd62b27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (64, 64, 64, 3) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# --- Plot ---\u001b[39;00m\n\u001b[32m      9\u001b[39m fig, axs = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m4\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43maxs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_d_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m axs[\u001b[32m0\u001b[39m].set_title(\u001b[33m\"\u001b[39m\u001b[33mClean\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m axs[\u001b[32m0\u001b[39m].axis(\u001b[33m\"\u001b[39m\u001b[33moff\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/matplotlib/__init__.py:1521\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1518\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1521\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1523\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1524\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1526\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1527\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1528\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5979\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5976\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5977\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5979\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5980\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5981\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5982\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/matplotlib/image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/global/u2/k/kberard/environments/SCGSR/lib/python3.12/site-packages/matplotlib/image.py:653\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    651\u001b[39m     A = A.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (A.ndim == \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A.shape[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m]):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for image data\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m:\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[32m    657\u001b[39m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[32m    658\u001b[39m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[32m    659\u001b[39m     high = \u001b[32m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.issubdtype(A.dtype, np.integer) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Invalid shape (64, 64, 64, 3) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_clean = ref_d_rgb            # shape: (64, 64, 3), dtype: float32\n",
    "                              # or whatever sampling parameter you want\n",
    "x_noisy = x_train_rgb[0] \n",
    "x_denoised = np.transpose(scunet_denoised, (0,2,1))\n",
    "print(x_denoised.shape)\n",
    "\n",
    "# --- Plot ---\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 4))\n",
    "axs[0].imshow(ref_d_rgb)\n",
    "axs[0].set_title(\"Clean\")\n",
    "axs[0].axis(\"off\")\n",
    "\n",
    "axs[1].imshow(x_noisy)\n",
    "axs[1].set_title(\"Noisy (Poisson)\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "\n",
    "axs[2].imshow(x_denoised)\n",
    "axs[2].set_title(\"Scu_Base Denoised Renorm\")\n",
    "axs[2].axis(\"off\")\n",
    "\n",
    "def normalize_per_sample(x_rgb):\n",
    "        max_vals = np.max(x_rgb, axis=(1, 2), keepdims=True)\n",
    "        max_vals = np.where(max_vals == 0, 1.0, max_vals)  # Prevent div by zero\n",
    "        return np.clip(x_rgb / (max_vals * 1), 0, 1)\n",
    "\n",
    "#might need to be renormalized because max is no longer 1\n",
    "renorm_den = normalize_per_sample(x_denoised)\n",
    "axs[3].imshow(renorm_den)\n",
    "axs[3].set_title(\"Scu_base Denoised Renorm\")\n",
    "axs[3].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c6cbee-e39d-4771-88f0-d295040f6d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72761f03-46e9-458c-b26c-4fb7376c3455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "3822.646322693739\n",
      "\n",
      "1.0\n",
      "2586.8709677419342\n",
      "\n",
      "0.97849387\n",
      "3641.4072\n",
      "\n",
      "1.0\n",
      "4315.4463\n"
     ]
    }
   ],
   "source": [
    "print(np.max(x_clean))\n",
    "print(np.sum(x_clean,axis=(0,1,2)))\n",
    "print()\n",
    "print(np.max(x_noisy))\n",
    "print(np.sum(x_noisy,axis=(0,1,2)))\n",
    "print()\n",
    "print(np.max(np.clip(x_denoised, 0, 1)))\n",
    "print(np.sum(np.clip(x_denoised, 0, 1),axis=(0,1,2)))\n",
    "print()\n",
    "print(np.max(np.clip(renorm_den, 0, 1)))\n",
    "print(np.sum(np.clip(renorm_den, 0, 1),axis=(0,1,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fbb6282-821d-4757-9c84-2b14448a3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jensen_shannon_divergence_loss(y_true, y_pred):\n",
    "    y_t = tf.cast(y_true, tf.float32)\n",
    "    y_p = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    y_t = tf.reshape(y_t, [tf.shape(y_t)[0], -1])\n",
    "    y_p = tf.reshape(y_p, [tf.shape(y_p)[0], -1])\n",
    "\n",
    "    y_t /= tf.reduce_sum(y_t, axis=1, keepdims=True) + 1e-8\n",
    "    y_p /= tf.reduce_sum(y_p, axis=1, keepdims=True) + 1e-8\n",
    "\n",
    "    m = 0.5 * (y_t + y_p)\n",
    "\n",
    "    kl_true = tf.reduce_sum(y_t * tf.math.log((y_t + 1e-8) / (m + 1e-8)), axis=1)\n",
    "    kl_pred = tf.reduce_sum(y_p * tf.math.log((y_p + 1e-8) / (m + 1e-8)), axis=1)\n",
    "\n",
    "    jsd = 0.5 * (kl_true + kl_pred)\n",
    "\n",
    "    return tf.reduce_mean(jsd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40483d90-776a-46fd-b9b5-9247bde2cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Evaluation Metrics on BM3D Denoised Image\n",
      "2-norm (x_denoised vs ref_d_rgb): 2.0683\n",
      "2-norm (renormalized vs ref_d_rgb): 7.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-29 10:18:25.136713: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753809505.148979 1923608 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753809505.152321 1923608 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753809505.162470 1923608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753809505.162485 1923608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753809505.162487 1923608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753809505.162488 1923608 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-29 10:18:25.166624: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1753809522.771033 1923608 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38366 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:03:00.0, compute capability: 8.0\n",
      "I0000 00:00:1753809522.775119 1923608 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38366 MB memory:  -> device: 1, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:41:00.0, compute capability: 8.0\n",
      "I0000 00:00:1753809522.777772 1923608 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 38366 MB memory:  -> device: 2, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:82:00.0, compute capability: 8.0\n",
      "I0000 00:00:1753809522.779783 1923608 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 38366 MB memory:  -> device: 3, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:c1:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSD (x_noisy vs ref_d_rgb): 0.012791\n",
      "JSD (x_denoised vs ref_d_rgb): 0.000297\n",
      "JSD (renormalized vs ref_d_rgb): 0.000297\n"
     ]
    }
   ],
   "source": [
    "# --- Evaluation ---\n",
    "print(\"\\n>>> Evaluation Metrics on BM3D Denoised Image\")\n",
    "\n",
    "# 2-norm difference (before/after renorm)\n",
    "norm_original = np.linalg.norm(x_denoised - x_clean)\n",
    "norm_renormed = np.linalg.norm(renorm_den - x_clean)\n",
    "\n",
    "print(f\"2-norm (x_denoised vs ref_d_rgb): {norm_original:.4f}\")\n",
    "print(f\"2-norm (renormalized vs ref_d_rgb): {norm_renormed:.4f}\")\n",
    "\n",
    "# Jensen-Shannon divergence setup\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import KLDivergence\n",
    "\n",
    "jsd_noisy = jensen_shannon_divergence_loss(tf.convert_to_tensor(x_noisy, dtype=tf.float32),\n",
    "                                               tf.convert_to_tensor(x_clean, dtype=tf.float32))\n",
    "jsd_original = jensen_shannon_divergence_loss(tf.convert_to_tensor(x_denoised, dtype=tf.float32),\n",
    "                                               tf.convert_to_tensor(x_clean, dtype=tf.float32))\n",
    "jsd_renormed = jensen_shannon_divergence_loss(tf.convert_to_tensor(renorm_den, dtype=tf.float32),\n",
    "                                               tf.convert_to_tensor(x_clean, dtype=tf.float32))\n",
    "print(f\"JSD (x_noisy vs ref_d_rgb): {jsd_noisy.numpy():.6f}\")\n",
    "print(f\"JSD (x_denoised vs ref_d_rgb): {jsd_original.numpy():.6f}\")\n",
    "print(f\"JSD (renormalized vs ref_d_rgb): {jsd_renormed.numpy():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ee2c6b-f520-4922-a27f-5a3311e51cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SCGSR",
   "language": "python",
   "name": "scgsr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
